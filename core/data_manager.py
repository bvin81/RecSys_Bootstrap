# core/data_manager.py
"""
GreenRec Data Manager
====================
Adatkezel√©si oszt√°ly, amely felel≈ës:
- JSON adatok bet√∂lt√©s√©√©rt √©s valid√°l√°s√°√©rt
- PostgreSQL kapcsolat kezel√©s√©√©rt
- Adatok el≈ëk√©sz√≠t√©s√©√©rt √©s normaliz√°l√°s√°√©rt
"""

import json
import logging
import pandas as pd
import numpy as np
from typing import Optional, Dict, List
import os
from config import current_config

logger = logging.getLogger(__name__)

class DataManager:
    """Adatkezel≈ë szolg√°ltat√°s"""
    
    def __init__(self):
        self.recipes_df: Optional[pd.DataFrame] = None
        self.is_loaded = False
    
    def load_recipe_data(self) -> pd.DataFrame:
        """
        Recept adatok bet√∂lt√©se JSON f√°jlb√≥l vagy demo adatok gener√°l√°sa
        
        Returns:
            pd.DataFrame: Bet√∂lt√∂tt √©s el≈ëk√©sz√≠tett recept adatok
        """
        if self.is_loaded and self.recipes_df is not None:
            return self.recipes_df
        
        try:
            # Els≈ëdleges adatf√°jl bet√∂lt√©se
            if os.path.exists(current_config.RECIPE_DATA_FILE):
                logger.info(f"Adatok bet√∂lt√©se: {current_config.RECIPE_DATA_FILE}")
                self.recipes_df = self._load_from_json(current_config.RECIPE_DATA_FILE)
            
            # Fallback f√°jl pr√≥b√°lkoz√°s
            elif os.path.exists(current_config.BACKUP_DATA_FILE):
                logger.info(f"Fallback adatok bet√∂lt√©se: {current_config.BACKUP_DATA_FILE}")
                self.recipes_df = self._load_from_json(current_config.BACKUP_DATA_FILE)
            
            # Demo adatok gener√°l√°sa ha nincs f√°jl
            else:
                logger.warning("Adatf√°jl nem tal√°lhat√≥, demo adatok gener√°l√°sa...")
                self.recipes_df = self._generate_demo_data()
            
            # Adatok el≈ëk√©sz√≠t√©se √©s normaliz√°l√°sa
            self.recipes_df = self._prepare_data(self.recipes_df)
            self.is_loaded = True
            
            logger.info(f"‚úÖ {len(self.recipes_df)} recept sikeresen bet√∂ltve")
            return self.recipes_df
            
        except Exception as e:
            logger.error(f"‚ùå Adatbet√∂lt√©si hiba: {e}")
            # Fallback demo adatokra
            self.recipes_df = self._generate_demo_data()
            self.recipes_df = self._prepare_data(self.recipes_df)
            self.is_loaded = True
            return self.recipes_df
    
    def _load_from_json(self, filepath: str) -> pd.DataFrame:
        """JSON f√°jl bet√∂lt√©se √©s DataFrame-m√© alak√≠t√°sa"""
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Lista vagy dict kezel√©se
        if isinstance(data, list):
            return pd.DataFrame(data)
        elif isinstance(data, dict):
            if 'recipes' in data:
                return pd.DataFrame(data['recipes'])
            else:
                return pd.DataFrame([data])
        else:
            raise ValueError(f"√ârv√©nytelen JSON strukt√∫ra: {type(data)}")
    
    def _generate_demo_data(self) -> pd.DataFrame:
        """Demo receptadatok gener√°l√°sa tesztel√©si c√©lokra"""
        np.random.seed(42)  # Reproduk√°lhat√≥ eredm√©nyek√©rt
        
        # Magyar √©telnevek
        dish_names = [
            "Guly√°sleves", "Schnitzel", "Lecs√≥", "P√∂rk√∂lt", "Hal√°szl√©",
            "Rakott Krumpli", "F≈ëzel√©k", "T√∫r√≥gomb√≥c", "L√°ngos", "K√ºrt≈ëskal√°cs",
            "Paprik√°skrumpli", "T√∂lt√∂tt K√°poszta", "Marhap√∂rk√∂lt", "Csirkepaprik√°s",
            "H√∫sgomb√≥c", "R√°ntott Szelet", "K√∂r√∂z√∂tt", "Zs√≠roskeny√©r",
            "Babguly√°s", "Pal√≥cleves", "J√≥kai Bableves", "√öjh√°zy Ty√∫kh√∫sleves",
            "G√∂d√∂ll≈ëi T√∂lt√∂tt Krumpli", "Erd√©lyi Rakottkrumpli", "Borj√∫p√∂rk√∂lt"
        ]
        
        # √ñsszetev≈ëk kateg√≥ri√°k
        ingredients_options = [
            "marhah√∫s, hagyma, paprika, krumpli, paradicsom",
            "csirkemell, rizs, z√∂lds√©g, f≈±szerek",
            "t√©szta, sajt, tejsz√≠n, sonka, bors",
            "hal, krumpli, hagyma, paprika, tejf√∂l",
            "sert√©sh√∫s, k√°poszta, rizs, toj√°s, f≈±szerek",
            "z√∂lds√©gek, ol√≠vaolaj, fokhagyma, gy√≥gyn√∂v√©nyek",
            "toj√°s, liszt, tej, vaj, cukor",
            "sal√°ta, paradicsom, uborka, olaj, ecet"
        ]
        
        n_recipes = 50
        
        demo_data = {
            'recipe_id': range(1, n_recipes + 1),
            'name': [f"{np.random.choice(dish_names)} #{i}" for i in range(1, n_recipes + 1)],
            'ingredients': [np.random.choice(ingredients_options) for _ in range(n_recipes)],
            'environmental_impact': np.random.randint(20, 80, n_recipes),  # ESI (alacsonyabb = jobb)
            'health_score': np.random.randint(30, 90, n_recipes),  # HSI (magasabb = jobb)
            'popularity': np.random.randint(40, 95, n_recipes),  # PPI (magasabb = jobb)
            'category': np.random.choice(['Leves', 'F≈ë√©tel', 'Sal√°ta', 'Desszert', 'Snack'], n_recipes),
            'preparation_time': np.random.randint(15, 120, n_recipes),  # percek
            'difficulty': np.random.choice(['K√∂nny≈±', 'K√∂zepes', 'Neh√©z'], n_recipes)
        }
        
        return pd.DataFrame(demo_data)
    
    def _prepare_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Adatok el≈ëk√©sz√≠t√©se √©s normaliz√°l√°sa
        
        Args:
            df: Nyers recept adatok
            
        Returns:
            pd.DataFrame: El≈ëk√©sz√≠tett adatok
        """
        df = df.copy()
        
        # ‚úÖ GREENREC_DATASET.JSON MEZ≈êK MAPPEL√âSE
        # JSON mez≈ëk ‚Üí Template mez≈ëk √°tnevez√©se
        field_mapping = {
            'recipeid': 'recipe_id',      # recipeid ‚Üí recipe_id
            'title': 'name',              # title ‚Üí name
            'images': 'image_url',        # images ‚Üí image_url
            # ESI, HSI, PPI m√°r j√≥ n√©ven vannak a JSON-ban
        }
        
        # Mez≈ëk √°tnevez√©se ha l√©teznek
        for old_name, new_name in field_mapping.items():
            if old_name in df.columns and new_name not in df.columns:
                df = df.rename(columns={old_name: new_name})
                logger.info(f"‚úÖ Mez≈ë √°tnevezve: {old_name} ‚Üí {new_name}")
        
        # K√∂telez≈ë oszlopok ellen≈ërz√©se √©s kieg√©sz√≠t√©se
        required_columns = {
            'recipe_id': list(range(1, len(df) + 1)),  # ‚Üê list() hozz√°ad√°sa
            'name': [f"Recept #{i}" for i in range(1, len(df) + 1)],
            'ingredients': ['alap√∂sszetev≈ëk'] * len(df),
            'ESI': [50] * len(df),  # Environmental Score Index
            'HSI': [60] * len(df),  # Health Score Index  
            'PPI': [70] * len(df),  # Popularity Index
            'category': ['Egy√©b'] * len(df),
            'image_url': [None] * len(df)
        }
        
        # Hi√°nyz√≥ oszlopok hozz√°ad√°sa
        for col, default_values in required_columns.items():
            if col not in df.columns:
                if isinstance(default_values, (list, np.ndarray)):
                    df[col] = default_values
                else:
                    df[col] = default_values
                logger.warning(f"‚ö†Ô∏è Hi√°nyz√≥ oszlop kieg√©sz√≠tve: {col}")
        
        # ‚úÖ ADATT√çPUSOK JAV√çT√ÅSA
        # Recipe ID biztosan integer legyen
        if 'recipe_id' in df.columns:
            df['recipe_id'] = pd.to_numeric(df['recipe_id'], errors='coerce').fillna(range(1, len(df) + 1)).astype(int)
        
        # Numerikus oszlopok
        for col in ['ESI', 'HSI', 'PPI']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(50.0)
        
        # String oszlopok tiszt√≠t√°sa
        for col in ['name', 'ingredients', 'category']:
            if col in df.columns:
                df[col] = df[col].astype(str).fillna("N/A")
        
        # ‚úÖ ESI INVERZ SZ√ÅM√çT√ÅS (alacsonyabb ESI = jobb k√∂rnyezeti hat√°s)
        if 'ESI' in df.columns:
            # ESI normaliz√°l√°sa 0-100 sk√°l√°ra
            esi_min, esi_max = df['ESI'].min(), df['ESI'].max()
            if esi_max > esi_min:
                df['esi_normalized'] = 100 * (df['ESI'] - esi_min) / (esi_max - esi_min)
            else:
                df['esi_normalized'] = [50] * len(df)
            
            # ESI inverz: 100 - normalized (magasabb √©rt√©k = jobb k√∂rnyezeti hat√°s)
            df['esi_inverted'] = 100 - df['esi_normalized']
            
            logger.info(f"‚úÖ ESI feldolgozva: {esi_min:.1f}-{esi_max:.1f} ‚Üí inverted")
        
        # ‚úÖ HSI √âS PPI NORMALIZ√ÅL√ÅS
        for col, new_col in [('HSI', 'health_score'), ('PPI', 'popularity')]:
            if col in df.columns:
                col_min, col_max = df[col].min(), df[col].max()
                if col_max > col_min:
                    df[f'{col.lower()}_normalized'] = 100 * (df[col] - col_min) / (col_max - col_min)
                else:
                    df[f'{col.lower()}_normalized'] = [50] * len(df)
                
                # Eredeti n√©v megtart√°sa kompatibilit√°s√©rt
                df[new_col] = df[col]
                logger.info(f"‚úÖ {col} normaliz√°lva")
        
        # ‚úÖ KOMPOZIT PONTSZ√ÅM SZ√ÅM√çT√ÅSA
        if all(col in df.columns for col in ['esi_inverted', 'HSI', 'PPI']):
            # S√∫lyozott √°tlag a config alapj√°n
            df['composite_score'] = (
                df['esi_inverted'] * current_config.ESI_WEIGHT +
                df.get('hsi_normalized', df['HSI']) * current_config.HSI_WEIGHT +
                df.get('ppi_normalized', df['PPI']) * current_config.PPI_WEIGHT
            )
            logger.info("‚úÖ Kompozit pontsz√°m kisz√°m√≠tva")
        
        # ‚úÖ K√âPEK URL VALID√ÅL√ÅSA
        if 'image_url' in df.columns:
            # Csak √©rv√©nyes HTTP URL-ek megtart√°sa
            df['image_url'] = df['image_url'].apply(
                lambda x: x if (isinstance(x, str) and x.startswith('http')) else None
            )
            
            # Placeholder k√©pek hi√°nyz√≥ esetekre
            missing_images = df['image_url'].isna().sum()
            if missing_images > 0:
                logger.info(f"‚ö†Ô∏è {missing_images} hi√°nyz√≥ k√©p URL")
        
        # ‚úÖ √ñSSZETEV≈êK SZ√ñVEG EL≈êK√âSZ√çT√âSE TF-IDF-hez
        if 'ingredients' in df.columns:
            df['ingredients_text'] = df['ingredients'].astype(str).str.lower()
        
        # ‚úÖ KATEG√ìRIA TISZT√çT√ÅS
        if 'category' in df.columns:
            # √úres kateg√≥ri√°k jav√≠t√°sa
            df['category'] = df['category'].fillna('Egy√©b')
            df['category'] = df['category'].replace('', 'Egy√©b')
        
        logger.info(f"‚úÖ Adatok el≈ëk√©sz√≠tve: {len(df)} recept, {len(df.columns)} oszlop")
        logger.info(f"üìä Oszlopok: {list(df.columns)}")
        
        return df
    
    def get_recipe_by_id(self, recipe_id: int) -> Optional[Dict]:
        """
        Recept lek√©rdez√©se ID alapj√°n
        
        Args:
            recipe_id: Recept azonos√≠t√≥
            
        Returns:
            Dict vagy None: Recept adatok
        """
        if self.recipes_df is None:
            self.load_recipe_data()
        
        recipe = self.recipes_df[self.recipes_df['recipe_id'] == recipe_id]
        if len(recipe) > 0:
            return recipe.iloc[0].to_dict()
        return None
    
    def get_recipes_by_category(self, category: str) -> pd.DataFrame:
        """Receptek lek√©rdez√©se kateg√≥ria alapj√°n"""
        if self.recipes_df is None:
            self.load_recipe_data()
        
        if 'category' in self.recipes_df.columns:
            return self.recipes_df[self.recipes_df['category'] == category]
        return pd.DataFrame()
    
    def get_data_statistics(self) -> Dict:
        """Adatok statisztik√°inak lek√©rdez√©se debug c√©lokra"""
        if self.recipes_df is None:
            self.load_recipe_data()
        
        return {
            'total_recipes': len(self.recipes_df),
            'esi_range': (self.recipes_df['esi_inverted'].min(), self.recipes_df['esi_inverted'].max()),
            'health_range': (self.recipes_df['health_score'].min(), self.recipes_df['health_score'].max()),
            'composite_range': (self.recipes_df['composite_score'].min(), self.recipes_df['composite_score'].max()),
            'categories': list(self.recipes_df.get('category', pd.Series()).unique()),
            'avg_composite_score': self.recipes_df['composite_score'].mean()
        }

# Glob√°lis data manager instance
data_manager = DataManager()

