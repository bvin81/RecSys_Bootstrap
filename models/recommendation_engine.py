# models/recommendation_engine.py - ML Aj√°nl√≥rendszer
"""
GreenRec Recommendation Engine
==============================
Machine Learning algoritmusok a receptaj√°nl√°sokhoz:
- Content-based filtering (TF-IDF + Cosine Similarity)
- ESI inverz normaliz√°l√°s √©s kompozit scoring
- A/B/C csoport algoritmusok
- Szem√©lyre szabott tanul√°s
"""

import pandas as pd
import numpy as np
import json
import random
import logging
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path
from typing import List, Dict, Any, Optional

from config import Config
from utils.data_processing import normalize_esi_scores, calculate_composite_scores
from utils.helpers import safe_int, safe_float

logger = logging.getLogger(__name__)

class RecommendationEngine:
    """
    GreenRec ML Aj√°nl√≥rendszer
    ==========================
    """
    
    def __init__(self):
        """Recommendation engine inicializ√°l√°sa"""
        self.recipes_df: Optional[pd.DataFrame] = None
        self.tfidf_vectorizer: Optional[TfidfVectorizer] = None
        self.tfidf_matrix = None
        self.initialized = False
        
        # Inicializ√°l√°s
        self._load_data()
        self._setup_ml_components()
    
    def _load_data(self):
        """Recept adatok bet√∂lt√©se"""
        logger.info("üìä Loading recipe data...")
        
        # Adatf√°jlok keres√©se
        data = None
        for filename in Config.DATA_FILES:
            try:
                file_path = Path(filename)
                if file_path.exists():
                    if filename.endswith('.json'):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        logger.info(f"‚úÖ JSON data loaded: {filename}")
                        break
                    elif filename.endswith('.csv'):
                        df = pd.read_csv(file_path, encoding='utf-8')
                        data = df.to_dict('records')
                        logger.info(f"‚úÖ CSV data loaded: {filename}")
                        break
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not load {filename}: {e}")
                continue
        
        # Fallback: demo adatok
        if data is None:
            logger.warning("‚ö†Ô∏è No data files found, generating demo data")
            data = self._generate_demo_data()
        
        # DataFrame l√©trehoz√°sa
        self.recipes_df = pd.DataFrame(data)
        self._process_recipe_data()
        
        logger.info(f"‚úÖ Loaded {len(self.recipes_df)} recipes")
    
    def _process_recipe_data(self):
        """Recept adatok feldolgoz√°sa √©s normaliz√°l√°sa"""
        logger.info("üîß Processing recipe data...")
        
        # ‚úÖ ESI INVERZ NORMALIZ√ÅL√ÅS
        if 'ESI' in self.recipes_df.columns:
            self.recipes_df = normalize_esi_scores(self.recipes_df)
            logger.info("‚úÖ ESI scores normalized and inverted")
        else:
            # Ha nincs ESI, random √©rt√©kek
            self.recipes_df['ESI_final'] = np.random.uniform(30, 80, len(self.recipes_df))
            logger.warning("‚ö†Ô∏è No ESI column found, using random values")
        
        # HSI √©s PPI ellen≈ërz√©se
        if 'HSI' not in self.recipes_df.columns:
            self.recipes_df['HSI'] = np.random.uniform(30, 95, len(self.recipes_df))
            logger.warning("‚ö†Ô∏è No HSI column found, using random values")
        
        if 'PPI' not in self.recipes_df.columns:
            self.recipes_df['PPI'] = np.random.uniform(20, 90, len(self.recipes_df))
            logger.warning("‚ö†Ô∏è No PPI column found, using random values")
        
        # ‚úÖ KOMPOZIT PONTSZ√ÅM SZ√ÅM√çT√ÅSA
        self.recipes_df = calculate_composite_scores(self.recipes_df, Config.SCORE_WEIGHTS)
        
        # Recept nevek √©s k√©pek biztos√≠t√°sa
        self._ensure_recipe_names_and_images()
        
        # Sz√ºks√©ges oszlopok ellen≈ërz√©se
        self._ensure_required_columns()
        
        # ID oszlop biztos√≠t√°sa
        if 'recipeid' not in self.recipes_df.columns and 'id' not in self.recipes_df.columns:
            self.recipes_df['recipeid'] = [f"recipe_{i+1}" for i in range(len(self.recipes_df))]
    
    def _ensure_recipe_names_and_images(self):
        """‚úÖ Recept nevek √©s k√©pek biztos√≠t√°sa"""
        
        # Recept nevek
        if 'recipe_name' not in self.recipes_df.columns and 'name' not in self.recipes_df.columns:
            hungarian_names = [
                "Guly√°sleves", "Schnitzel burgony√°val", "L√°ngos", "Hal√°szl√©",
                "Paprikash csirk√©vel", "T√∂lt√∂tt k√°poszta", "Lecs√≥", "K√ºrt≈ëskal√°cs",
                "T√∫r√≥s csusza", "Bableves", "Rost√©lyos", "R√°ntott sajt",
                "Goulash", "Cs√∂r√∂gef√°nk", "T√∫r√≥gomb√≥c", "Wiener Schnitzel",
                "Stef√°nia szelet", "M√°kos guba", "Soml√≥i galuska", "Dobostorta",
                "Veg√°n curry", "Quinoa sal√°ta", "Avok√°d√≥ toast", "Green smoothie",
                "Buddha bowl", "Lencsecurry", "Veg√°n pizza", "Chia puding",
                "Mandulatejes zabk√°sa", "Spen√≥tos lasagne", "Thai curry",
                "Pad thai", "Ramen leves", "Pho leves", "Caesar sal√°ta",
                "G√∂r√∂g sal√°ta", "Caprese sal√°ta", "Waldorf sal√°ta", "Tiramisu",
                "Panna cotta", "Brownie", "Granola bowl", "Smoothie bowl",
                "Acai bowl", "Overnight oats", "French toast", "Pancakes",
                "Muesli", "Fruit salad", "Energy balls", "Protein smoothie"
            ]
            
            self.recipes_df['recipe_name'] = [
                random.choice(hungarian_names) for _ in range(len(self.recipes_df))
            ]
        
        # K√©pek URL-jei
        if 'image_url' not in self.recipes_df.columns and 'images' not in self.recipes_df.columns:
            self.recipes_df['image_url'] = [
                f"{Config.IMAGE_PLACEHOLDER_BASE}{i+100}" 
                for i in range(len(self.recipes_df))
            ]
        
        # Fallback name oszlopra
        if 'recipe_name' not in self.recipes_df.columns and 'name' in self.recipes_df.columns:
            self.recipes_df['recipe_name'] = self.recipes_df['name']
    
    def _ensure_required_columns(self):
        """Sz√ºks√©ges oszlopok biztos√≠t√°sa"""
        required_columns = {
            'category': ['F≈ë√©tel', 'Leves', 'Sal√°ta', 'Desszert', 'Snack', 'Reggeli'],
            'ingredients': ['hagyma, fokhagyma, paradicsom, paprika, ol√≠vaolaj']
        }
        
        for col, default_values in required_columns.items():
            if col not in self.recipes_df.columns:
                if isinstance(default_values, list) and len(default_values) > 1:
                    self.recipes_df[col] = [
                        random.choice(default_values) for _ in range(len(self.recipes_df))
                    ]
                else:
                    self.recipes_df[col] = default_values[0]
                logger.info(f"‚úÖ Added missing column: {col}")
    
    def _setup_ml_components(self):
        """Machine learning komponensek inicializ√°l√°sa"""
        logger.info("ü§ñ Setting up ML components...")
        
        try:
            # TF-IDF vektoriz√°ci√≥
            content = []
            for _, recipe in self.recipes_df.iterrows():
                recipe_name = recipe.get('recipe_name', recipe.get('name', ''))
                category = recipe.get('category', '')
                ingredients = recipe.get('ingredients', '')
                text = f"{recipe_name} {category} {ingredients}"
                content.append(text.lower())
            
            # TF-IDF inicializ√°l√°sa
            self.tfidf_vectorizer = TfidfVectorizer(
                max_features=Config.TFIDF_MAX_FEATURES,
                ngram_range=Config.TFIDF_NGRAM_RANGE,
                stop_words=None  # Magyar szavakhoz nincs be√©p√≠tett stop words
            )
            
            self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(content)
            
            self.initialized = True
            logger.info("‚úÖ TF-IDF vectorizer initialized")
            logger.info(f"üìä TF-IDF matrix shape: {self.tfidf_matrix.shape}")
            
        except Exception as e:
            logger.error(f"‚ùå ML setup error: {e}")
            self.initialized = False
    
    def _generate_demo_data(self) -> List[Dict]:
        """Demo receptek gener√°l√°sa"""
        categories = ['F≈ë√©tel', 'Leves', 'Sal√°ta', 'Desszert', 'Snack', 'Reggeli']
        ingredients_lists = [
            'hagyma, fokhagyma, paradicsom, paprika, ol√≠vaolaj',
            'csirkemell, brokkoli, rizs, sz√≥jasz√≥sz, gy√∂mb√©r',
            'sal√°ta, uborka, paradicsom, ol√≠vaolaj, citrom',
            'toj√°s, liszt, cukor, vaj, van√≠lia, csokol√°d√©',
            'mandula, di√≥, m√©z, zabpehely, √°fonya, ban√°n',
            'avok√°d√≥, spen√≥t, ban√°n, chia mag, k√≥kusztej',
            'quinoa, fekete bab, kukorica, lime, koriander',
            'lazac, sp√°rga, citrom, ol√≠vaolaj, fokhagyma'
        ]
        
        recipe_names = [
            "Magyaros guly√°s", "Z√∂lds√©ges curry", "Caesar sal√°ta", "Csokol√°d√© mousse",
            "Granola bowl", "Avok√°d√≥ toast", "Pad thai", "G√∂r√∂g sal√°ta",
            "Tiramisu", "Smoothie bowl", "Ramen leves", "Caprese sal√°ta",
            "Brownie", "Acai bowl", "Thai curry", "Quinoa sal√°ta",
            "Panna cotta", "Chia puding", "Pho leves", "Waldorf sal√°ta",
            "L√°ngos", "Hal√°szl√©", "K√ºrt≈ëskal√°cs", "Lecs√≥",
            "T√∫r√≥s csusza", "Schnitzel", "Goulash", "Paprikash",
            "Energy balls", "Green smoothie", "Buddha bowl", "Overnight oats"
        ]
        
        demo_recipes = []
        for i in range(60):  # T√∂bb demo recept
            demo_recipes.append({
                'recipeid': f'demo_recipe_{i+1}',
                'recipe_name': recipe_names[i % len(recipe_names)],
                'category': random.choice(categories),
                'ingredients': random.choice(ingredients_lists),
                'image_url': f"{Config.IMAGE_PLACEHOLDER_BASE}{i+200}",
                'ESI': random.uniform(10, 90),  # K√∂rnyezeti hat√°s (magasabb = rosszabb)
                'HSI': random.uniform(30, 95),  # Eg√©szs√©g√ºgyi (magasabb = jobb)
                'PPI': random.uniform(20, 90)   # N√©pszer≈±s√©g (magasabb = jobb)
            })
        
        return demo_recipes
    
    # ============================================
    # AJ√ÅNL√ÅSI ALGORITMUSOK
    # ============================================
    
    def get_personalized_recommendations(self, user_id: str, user_group: str, 
                                       learning_round: int, previous_ratings: Dict,
                                       n: int = 5) -> pd.DataFrame:
        """
        Szem√©lyre szabott aj√°nl√°sok gener√°l√°sa A/B/C csoportok szerint
        """
        if not self.initialized:
            logger.error("‚ùå Recommendation engine not initialized")
            return pd.DataFrame()
        
        try:
            # 1. k√∂r: Random receptek (baseline minden csoportnak)
            if learning_round == 1 or not previous_ratings:
                selected = self.recipes_df.sample(n=min(n, len(self.recipes_df)))
                logger.info(f"üé≤ Random recommendations for {user_group} (round {learning_round})")
                return selected
            
            # 2+ k√∂r: Csoportonk√©nti algoritmusok
            return self._get_algorithm_specific_recommendations(
                user_group, previous_ratings, n
            )
            
        except Exception as e:
            logger.error(f"‚ùå Recommendation generation error: {e}")
            # Fallback: random receptek
            return self.recipes_df.sample(n=min(n, len(self.recipes_df)))
    
    def _get_algorithm_specific_recommendations(self, user_group: str, 
                                              previous_ratings: Dict, n: int) -> pd.DataFrame:
        """Csoportonk√©nti aj√°nl√°si algoritmusok"""
        
        # Kedvelt receptek elemz√©se (rating >= 4)
        liked_recipe_ids = [
            rid for rid, rating in previous_ratings.items() 
            if rating >= Config.RELEVANCE_THRESHOLD
        ]
        
        if not liked_recipe_ids:
            # Ha nincs kedvelt recept, magas kompozit pontsz√°m√∫akat aj√°nljunk
            selected = self.recipes_df.nlargest(n, 'composite_score')
            logger.info(f"üìä High-score fallback for group {user_group}")
            return selected
        
        # Preferenci√°k tanul√°sa
        liked_recipes = self.recipes_df[
            self.recipes_df['recipeid'].isin(liked_recipe_ids)
        ]
        
        if len(liked_recipes) == 0:
            return self.recipes_df.sample(n=min(n, len(self.recipes_df)))
        
        # M√©g nem √©rt√©kelt receptek
        unrated_recipes = self.recipes_df[
            ~self.recipes_df['recipeid'].isin(previous_ratings.keys())
        ].copy()
        
        if len(unrated_recipes) == 0:
            return self.recipes_df.sample(n=min(n, len(self.recipes_df)))
        
        # Csoportonk√©nti algoritmusok
        if user_group == 'A':
            # ‚úÖ Content-based (REJTETT pontsz√°mok)
            selected = self._content_based_algorithm(liked_recipes, unrated_recipes, n)
            
        elif user_group == 'B':
            # Score-enhanced (pontsz√°mok L√ÅTHAT√ìK)
            selected = self._score_enhanced_algorithm(liked_recipes, unrated_recipes, n)
            
        else:  # user_group == 'C'
            # Hybrid + XAI (pontsz√°mok + magyar√°zatok)
            selected = self._hybrid_xai_algorithm(liked_recipes, unrated_recipes, n)
        
        logger.info(f"üéØ {user_group} algorithm: {len(selected)} recommendations")
        return selected
    
    def _content_based_algorithm(self, liked_recipes: pd.DataFrame, 
                                unrated_recipes: pd.DataFrame, n: int) -> pd.DataFrame:
        """A csoport: Content-based filtering (rejtett pontsz√°mok)"""
        
        # Kateg√≥ria preferenci√°k
        preferred_categories = liked_recipes['category'].value_counts().index.tolist()
        
        # Egyszer≈± kateg√≥ria-alap√∫ scoring
        unrated_recipes['score'] = unrated_recipes['category'].apply(
            lambda cat: 3.0 if cat in preferred_categories[:2] else 
                       2.0 if cat in preferred_categories[:4] else 1.0
        )
        
        # Random komponens hozz√°ad√°sa a diverzit√°s√©rt
        unrated_recipes['score'] += np.random.uniform(0, 0.5, len(unrated_recipes))
        
        return unrated_recipes.nlargest(n, 'score')
    
    def _score_enhanced_algorithm(self, liked_recipes: pd.DataFrame,
                                 unrated_recipes: pd.DataFrame, n: int) -> pd.DataFrame:
        """B csoport: Score-enhanced recommendations"""
        
        # Kateg√≥ria √©s pontsz√°m preferenci√°k
        preferred_categories = liked_recipes['category'].value_counts().index.tolist()
        avg_composite = liked_recipes['composite_score'].mean()
        
        # Kateg√≥ria boost
        category_boost = unrated_recipes['category'].apply(
            lambda cat: 30 if cat in preferred_categories[:2] else 
                       20 if cat in preferred_categories[:4] else 10
        )
        
        # Kompozit pontsz√°m similarit√°s
        composite_similarity = 1 - np.abs(unrated_recipes['composite_score'] - avg_composite) / 100
        
        # Kombin√°lt scoring
        unrated_recipes['score'] = (
            unrated_recipes['composite_score'] * 0.5 +
            category_boost * 0.3 +
            composite_similarity * 20 * 0.2
        )
        
        return unrated_recipes.nlargest(n, 'score')
    
    def _hybrid_xai_algorithm(self, liked_recipes: pd.DataFrame,
                             unrated_recipes: pd.DataFrame, n: int) -> pd.DataFrame:
        """C csoport: Hybrid + XAI approach"""
        
        # √ñsszes preferencia t√≠pus figyelembev√©tele
        preferred_categories = liked_recipes['category'].value_counts().index.tolist()
        avg_esi = liked_recipes['ESI_final'].mean()
        avg_hsi = liked_recipes['HSI'].mean()
        avg_ppi = liked_recipes['PPI'].mean()
        
        # Multi-dimensional similarity
        esi_similarity = 1 - np.abs(unrated_recipes['ESI_final'] - avg_esi) / 100
        hsi_similarity = 1 - np.abs(unrated_recipes['HSI'] - avg_hsi) / 100
        ppi_similarity = 1 - np.abs(unrated_recipes['PPI'] - avg_ppi) / 100
        
        # Kateg√≥ria boost
        category_boost = unrated_recipes['category'].apply(
            lambda cat: 2.5 if cat in preferred_categories[:2] else 
                       1.5 if cat in preferred_categories[:4] else 1.0
        )
        
        # Kombin√°lt scoring (leg√∂sszetettebb)
        unrated_recipes['score'] = (
            esi_similarity * 25 +      # K√∂rnyezeti hasonl√≥s√°g
            hsi_similarity * 25 +      # Eg√©szs√©g√ºgyi hasonl√≥s√°g  
            ppi_similarity * 15 +      # N√©pszer≈±s√©gi hasonl√≥s√°g
            category_boost * 15 +      # Kateg√≥ria preferencia
            unrated_recipes['composite_score'] * 0.2  # Abszol√∫t pontsz√°m
        )
        
        return unrated_recipes.nlargest(n, 'score')
    
    # ============================================
    # KERES√âSI FUNKCI√ìK
    # ============================================
    
    def search_by_ingredients(self, query: str, limit: int = 15) -> List[Dict]:
        """√ñsszetev≈ëk alapj√°n recept keres√©s TF-IDF hasonl√≥s√°ggal"""
        
        if not self.initialized or not query or len(query.strip()) < 2:
            return []
        
        try:
            # Query vektoriz√°l√°sa
            query_vector = self.tfidf_vectorizer.transform([query.lower()])
            
            # Cosine similarity sz√°m√≠t√°sa
            similarities = cosine_similarity(query_vector, self.tfidf_matrix).flatten()
            
            # Top eredm√©nyek kiv√°laszt√°sa
            top_indices = similarities.argsort()[-limit:][::-1]
            
            results = []
            for idx in top_indices:
                if similarities[idx] > Config.SEARCH_MIN_SIMILARITY:
                    recipe = self.recipes_df.iloc[idx]
                    results.append({
                        'recipeid': recipe.get('recipeid', f'recipe_{idx}'),
                        'recipe_name': recipe.get('recipe_name', recipe.get('name', f'Recept {idx+1}')),
                        'category': recipe.get('category', ''),
                        'ingredients': recipe.get('ingredients', ''),
                        'image_url': recipe.get('image_url', recipe.get('images', Config.DEFAULT_RECIPE_IMAGE)),
                        'similarity': round(similarities[idx], 3),
                        'composite_score': round(recipe.get('composite_score', 0), 1),
                        'ESI_final': round(recipe.get('ESI_final', 0), 1),
                        'HSI': round(recipe.get('HSI', 0), 1),
                        'PPI': round(recipe.get('PPI', 0), 1)
                    })
            
            logger.info(f"üîç Search '{query}' returned {len(results)} results")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Search error: {e}")
            return []
    
    # ============================================
    # UTILITY √âS STATUS FUNKCI√ìK
    # ============================================
    
    def is_initialized(self) -> bool:
        """Engine inicializ√°l√°si √°llapot"""
        return self.initialized and self.recipes_df is not None
    
    def tfidf_ready(self) -> bool:
        """TF-IDF ready √°llapot"""
        return self.tfidf_vectorizer is not None and self.tfidf_matrix is not None
    
    def get_recipe_count(self) -> int:
        """Bet√∂lt√∂tt receptek sz√°ma"""
        return len(self.recipes_df) if self.recipes_df is not None else 0
    
    def get_recipe_by_id(self, recipe_id: str) -> Optional[Dict]:
        """Recept lek√©r√©se ID alapj√°n"""
        if not self.initialized:
            return None
        
        try:
            recipe = self.recipes_df[self.recipes_df['recipeid'] == recipe_id]
            if len(recipe) > 0:
                return recipe.iloc[0].to_dict()
            return None
        except Exception as e:
            logger.error(f"‚ùå Recipe lookup error: {e}")
            return None
    
    def get_data_statistics(self) -> Dict:
        """Adatok statisztik√°i"""
        if not self.initialized:
            return {}
        
        try:
            stats = {
                'total_recipes': len(self.recipes_df),
                'categories': self.recipes_df['category'].value_counts().to_dict(),
                'score_ranges': {
                    'ESI_final': {
                        'min': float(self.recipes_df['ESI_final'].min()),
                        'max': float(self.recipes_df['ESI_final'].max()),
                        'mean': float(self.recipes_df['ESI_final'].mean())
                    },
                    'HSI': {
                        'min': float(self.recipes_df['HSI'].min()),
                        'max': float(self.recipes_df['HSI'].max()),
                        'mean': float(self.recipes_df['HSI'].mean())
                    },
                    'PPI': {
                        'min': float(self.recipes_df['PPI'].min()),
                        'max': float(self.recipes_df['PPI'].max()),
                        'mean': float(self.recipes_df['PPI'].mean())
                    },
                    'composite_score': {
                        'min': float(self.recipes_df['composite_score'].min()),
                        'max': float(self.recipes_df['composite_score'].max()),
                        'mean': float(self.recipes_df['composite_score'].mean())
                    }
                },
                'tfidf_features': self.tfidf_matrix.shape[1] if self.tfidf_matrix is not None else 0,
                'missing_images': len(self.recipes_df[self.recipes_df['image_url'].isna()]) if 'image_url' in self.recipes_df.columns else 0
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå Statistics calculation error: {e}")
            return {}
    
    def refresh_data(self):
        """Adatok √∫jrat√∂lt√©se √©s ML komponensek √∫jrainicializ√°l√°sa"""
        logger.info("üîÑ Refreshing recommendation engine data...")
        
        self.initialized = False
        self.recipes_df = None
        self.tfidf_vectorizer = None
        self.tfidf_matrix = None
        
        # √öjrainicializ√°l√°s
        self._load_data()
        self._setup_ml_components()
        
        logger.info("‚úÖ Recommendation engine refreshed")
    
    def get_random_recipes(self, n: int = 5) -> pd.DataFrame:
        """Random receptek lek√©r√©se (fallback funkci√≥hoz)"""
        if not self.initialized:
            return pd.DataFrame()
        
        return self.recipes_df.sample(n=min(n, len(self.recipes_df)))
    
    def validate_engine(self) -> Dict[str, bool]:
        """Engine valid√°l√°sa √©s hibaellen≈ërz√©s"""
        validation_results = {
            'data_loaded': self.recipes_df is not None,
            'has_recipes': len(self.recipes_df) > 0 if self.recipes_df is not None else False,
            'has_required_columns': False,
            'tfidf_initialized': self.tfidf_vectorizer is not None,
            'tfidf_matrix_ready': self.tfidf_matrix is not None,
            'scores_calculated': False,
            'images_available': False
        }
        
        if self.recipes_df is not None:
            required_cols = ['recipeid', 'recipe_name', 'category', 'ingredients', 'ESI_final', 'HSI', 'PPI', 'composite_score']
            validation_results['has_required_columns'] = all(col in self.recipes_df.columns for col in required_cols)
            
            validation_results['scores_calculated'] = 'composite_score' in self.recipes_df.columns
            validation_results['images_available'] = 'image_url' in self.recipes_df.columns
        
        # √ñsszes√≠tett validation
        validation_results['overall_valid'] = all([
            validation_results['data_loaded'],
            validation_results['has_recipes'],
            validation_results['has_required_columns'],
            validation_results['tfidf_initialized'],
            validation_results['scores_calculated']
        ])
        
        return validation_results

# ============================================
# SINGLETON PATTERN IMPLEMENTATION
# ============================================

_recommendation_engine_instance = None

def get_recommendation_engine() -> RecommendationEngine:
    """Singleton pattern - egyetlen engine instance"""
    global _recommendation_engine_instance
    
    if _recommendation_engine_instance is None:
        _recommendation_engine_instance = RecommendationEngine()
        logger.info("‚úÖ Recommendation engine singleton created")
    
    return _recommendation_engine_instance

def reset_recommendation_engine():
    """Engine reset (testing/debugging c√©lokra)"""
    global _recommendation_engine_instance
    _recommendation_engine_instance = None
    logger.info("üîÑ Recommendation engine singleton reset")

# Export
__all__ = ['RecommendationEngine', 'get_recommendation_engine', 'reset_recommendation_engine']
