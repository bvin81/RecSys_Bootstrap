# utils/data_processing.py - Adatfeldolgoz√°si Funkci√≥k
"""
GreenRec Data Processing Utilities
==================================
Adatfeldolgoz√°si √©s normaliz√°l√°si funkci√≥k:
- ESI inverz normaliz√°l√°s (100-ESI)
- Kompozit pontsz√°m sz√°m√≠t√°sa
- Adattiszt√≠t√°s √©s valid√°ci√≥
- Feature engineering
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, Any, Optional, Tuple

logger = logging.getLogger(__name__)

def normalize_esi_scores(df: pd.DataFrame) -> pd.DataFrame:
    """
    ‚úÖ ESI inverz normaliz√°l√°s implement√°l√°sa
    
    Steps:
    1. ESI normaliz√°l√°s 0-100 k√∂z√©
    2. Inverz sz√°m√≠t√°s: 100 - normaliz√°lt_ESI
    3. Magasabb ESI = rosszabb k√∂rnyezetterhel√©s ‚Üí alacsonyabb ESI_final √©rt√©k
    
    Args:
        df: DataFrame ESI oszloppal
    
    Returns:
        DataFrame ESI_final oszloppal
    """
    df = df.copy()
    
    try:
        if 'ESI' not in df.columns:
            logger.warning("‚ö†Ô∏è No ESI column found")
            df['ESI_final'] = np.random.uniform(30, 80, len(df))
            return df
        
        # ESI √©rt√©kek valid√°l√°sa √©s tiszt√≠t√°sa
        df['ESI'] = pd.to_numeric(df['ESI'], errors='coerce')
        df['ESI'].fillna(df['ESI'].median(), inplace=True)
        
        # Min-max normaliz√°l√°s 0-100 k√∂z√©
        esi_min = df['ESI'].min()
        esi_max = df['ESI'].max()
        
        if esi_max > esi_min:
            # Normaliz√°l√°s
            df['ESI_normalized'] = 100 * (df['ESI'] - esi_min) / (esi_max - esi_min)
            
            # ‚úÖ INVERZ SZ√ÅM√çT√ÅS
            df['ESI_final'] = 100 - df['ESI_normalized']
            
            logger.info(f"‚úÖ ESI normalization: {esi_min:.1f}-{esi_max:.1f} ‚Üí 0-100 (inverted)")
            logger.info(f"üìä ESI_final range: {df['ESI_final'].min():.1f}-{df['ESI_final'].max():.1f}")
        else:
            # Ha minden ESI √©rt√©k ugyanaz
            df['ESI_final'] = 50.0  # Neutral √©rt√©k
            logger.warning("‚ö†Ô∏è All ESI values are the same, using neutral value")
        
        return df
        
    except Exception as e:
        logger.error(f"‚ùå ESI normalization error: {e}")
        # Fallback: random √©rt√©kek
        df['ESI_final'] = np.random.uniform(30, 80, len(df))
        return df

def calculate_composite_scores(df: pd.DataFrame, weights: Dict[str, float]) -> pd.DataFrame:
    """
    ‚úÖ Kompozit pontsz√°m sz√°m√≠t√°sa helyes k√©plettel
    
    Formula: ESI_final * 0.4 + HSI * 0.4 + PPI * 0.2
    
    Args:
        df: DataFrame pontsz√°m oszlopokkal
        weights: S√∫lyoz√°si be√°ll√≠t√°sok {'ESI': 0.4, 'HSI': 0.4, 'PPI': 0.2}
    
    Returns:
        DataFrame composite_score oszloppal
    """
    df = df.copy()
    
    try:
        # Sz√ºks√©ges oszlopok ellen≈ërz√©se
        required_columns = ['ESI_final', 'HSI', 'PPI']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logger.error(f"‚ùå Missing columns for composite score: {missing_columns}")
            df['composite_score'] = 50.0  # Default √©rt√©k
            return df
        
        # Adatok valid√°l√°sa √©s tiszt√≠t√°sa
        for col in required_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
            df[col].fillna(df[col].median(), inplace=True)
        
        # ‚úÖ KOMPOZIT PONTSZ√ÅM SZ√ÅM√çT√ÅSA
        df['composite_score'] = (
            df['ESI_final'] * weights['ESI'] +     # K√∂rnyezeti (inverz ESI)
            df['HSI'] * weights['HSI'] +           # Eg√©szs√©g√ºgyi
            df['PPI'] * weights['PPI']             # N√©pszer≈±s√©gi
        ).round(1)
        
        # Valid√°l√°s: 0-100 k√∂z√∂tt kell legyen
        df['composite_score'] = df['composite_score'].clip(0, 100)
        
        logger.info(f"‚úÖ Composite scores calculated")
        logger.info(f"üìä Composite range: {df['composite_score'].min():.1f}-{df['composite_score'].max():.1f}")
        logger.info(f"‚öñÔ∏è Weights used: ESI={weights['ESI']}, HSI={weights['HSI']}, PPI={weights['PPI']}")
        
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Composite score calculation error: {e}")
        # Fallback: random √©rt√©kek
        df['composite_score'] = np.random.uniform(20, 90, len(df))
        return df

def clean_recipe_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Recept adatok tiszt√≠t√°sa √©s valid√°l√°sa
    
    Args:
        df: Nyers recept DataFrame
    
    Returns:
        Tiszt√≠tott DataFrame
    """
    df = df.copy()
    
    try:
        logger.info("üßπ Cleaning recipe data...")
        
        # Duplik√°lt sorok elt√°vol√≠t√°sa
        initial_count = len(df)
        df.drop_duplicates(inplace=True)
        if len(df) < initial_count:
            logger.info(f"üóëÔ∏è Removed {initial_count - len(df)} duplicate rows")
        
        # Sz√∂veges oszlopok tiszt√≠t√°sa
        text_columns = ['recipe_name', 'name', 'category', 'ingredients']
        for col in text_columns:
            if col in df.columns:
                # Whitespace √©s √ºres √©rt√©kek kezel√©se
                df[col] = df[col].astype(str).str.strip()
                df[col] = df[col].replace(['', 'nan', 'None'], np.nan)
                
                # Alap√©rtelmezett √©rt√©kek
                if col in ['recipe_name', 'name']:
                    df[col].fillna('N√©vtelen recept', inplace=True)
                elif col == 'category':
                    df[col].fillna('Egy√©b', inplace=True)
                elif col == 'ingredients':
                    df[col].fillna('√ñsszetev≈ëk nem megadottak', inplace=True)
        
        # Numerikus oszlopok tiszt√≠t√°sa
        numeric_columns = ['ESI', 'HSI', 'PPI']
        for col in numeric_columns:
            if col in df.columns:
                # Numerikus konverzi√≥
                df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # Outlier kezel√©s (99%-os percentile)
                if col == 'ESI':
                    # ESI eset√©n 0-100+ tartom√°ny elfogadhat√≥
                    df[col] = df[col].clip(0, None)
                else:
                    # HSI, PPI eset√©n 0-100 tartom√°ny
                    df[col] = df[col].clip(0, 100)
                
                # Hi√°nyz√≥ √©rt√©kek p√≥tl√°sa medi√°nnal
                median_value = df[col].median()
                df[col].fillna(median_value, inplace=True)
        
        # URL oszlopok tiszt√≠t√°sa
        if 'image_url' in df.columns:
            df['image_url'] = df['image_url'].astype(str)
            # √ârv√©nytelen URL-ek kezel√©se
            invalid_urls = df['image_url'].isin(['nan', 'None', '', 'null'])
            df.loc[invalid_urls, 'image_url'] = np.nan
        
        logger.info(f"‚úÖ Data cleaning completed: {len(df)} records")
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Data cleaning error: {e}")
        return df

def validate_recipe_dataframe(df: pd.DataFrame) -> Tuple[bool, list]:
    """
    DataFrame valid√°l√°sa receptekhez
    
    Args:
        df: Valid√°land√≥ DataFrame
    
    Returns:
        (is_valid, error_list)
    """
    errors = []
    
    try:
        # Alapvet≈ë ellen≈ërz√©sek
        if df is None or len(df) == 0:
            errors.append("DataFrame is empty")
            return False, errors
        
        # Sz√ºks√©ges oszlopok ellen≈ërz√©se
        required_columns = ['recipe_name', 'category', 'ingredients']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            errors.append(f"Missing required columns: {missing_columns}")
        
        # ID oszlop ellen≈ërz√©se
        id_columns = ['recipeid', 'id']
        has_id = any(col in df.columns for col in id_columns)
        if not has_id:
            errors.append("No ID column found (recipeid or id)")
        
        # Pontsz√°m oszlopok ellen≈ërz√©se
        score_columns = ['ESI', 'HSI', 'PPI']
        missing_scores = [col for col in score_columns if col not in df.columns]
        if missing_scores:
            errors.append(f"Missing score columns: {missing_scores}")
        
        # Adatmin≈ës√©g ellen≈ërz√©sek
        if len(df) < 10:
            errors.append(f"Too few recipes: {len(df)} (minimum 10 recommended)")
        
        # Numerikus oszlopok ellen≈ërz√©se
        for col in ['ESI', 'HSI', 'PPI']:
            if col in df.columns:
                non_numeric = df[col].isna().sum()
                if non_numeric > len(df) * 0.5:  # 50%-n√°l t√∂bb hi√°nyz√≥ √©rt√©k
                    errors.append(f"Too many missing values in {col}: {non_numeric}/{len(df)}")
        
        # Sz√∂veges oszlopok ellen≈ërz√©se
        for col in ['recipe_name', 'category', 'ingredients']:
            if col in df.columns:
                empty_values = df[col].isna().sum()
                if empty_values > len(df) * 0.1:  # 10%-n√°l t√∂bb hi√°nyz√≥ √©rt√©k
                    errors.append(f"Too many missing values in {col}: {empty_values}/{len(df)}")
        
        is_valid = len(errors) == 0
        
        if is_valid:
            logger.info("‚úÖ DataFrame validation passed")
        else:
            logger.warning(f"‚ö†Ô∏è DataFrame validation failed: {len(errors)} errors")
            for error in errors:
                logger.warning(f"  - {error}")
        
        return is_valid, errors
        
    except Exception as e:
        logger.error(f"‚ùå Validation error: {e}")
        return False, [f"Validation exception: {str(e)}"]

def add_feature_engineering(df: pd.DataFrame) -> pd.DataFrame:
    """
    Feature engineering recept adatokon
    
    Args:
        df: Alap recept DataFrame
    
    Returns:
        DataFrame tov√°bbi feature oszlopokkal
    """
    df = df.copy()
    
    try:
        logger.info("üîß Adding feature engineering...")
        
        # √ñsszetev≈ëk sz√°ma
        if 'ingredients' in df.columns:
            df['ingredient_count'] = df['ingredients'].str.count(',') + 1
            df['ingredient_count'].fillna(1, inplace=True)
        
        # Kateg√≥ria encoding
        if 'category' in df.columns:
            df['is_main_course'] = (df['category'] == 'F≈ë√©tel').astype(int)
            df['is_healthy'] = df['category'].isin(['Sal√°ta', 'Smoothie', 'Veg√°n']).astype(int)
            df['is_dessert'] = (df['category'] == 'Desszert').astype(int)
        
        # Pontsz√°m kateg√≥ri√°k
        if 'composite_score' in df.columns:
            df['score_category'] = pd.cut(
                df['composite_score'], 
                bins=[0, 40, 70, 100], 
                labels=['Low', 'Medium', 'High']
            )
        
        # Fenntarthat√≥s√°gi kateg√≥ri√°k
        if 'ESI_final' in df.columns:
            df['sustainability_level'] = pd.cut(
                df['ESI_final'],
                bins=[0, 33, 66, 100],
                labels=['Low', 'Medium', 'High']
            )
        
        # Eg√©szs√©g√ºgyi kateg√≥ri√°k
        if 'HSI' in df.columns:
            df['health_level'] = pd.cut(
                df['HSI'],
                bins=[0, 40, 70, 100],
                labels=['Low', 'Medium', 'High']
            )
        
        # √ñsszes√≠tett kateg√≥ria
        if all(col in df.columns for col in ['ESI_final', 'HSI']):
            df['recommended_level'] = 'Basic'
            
            # Magas ESI_final √âS magas HSI = er≈ësen aj√°nlott
            high_sustain = df['ESI_final'] > 70
            high_health = df['HSI'] > 70
            df.loc[high_sustain & high_health, 'recommended_level'] = 'Highly Recommended'
            
            # K√∂zepes √©rt√©kek = aj√°nlott
            medium_sustain = (df['ESI_final'] > 40) & (df['ESI_final'] <= 70)
            medium_health = (df['HSI'] > 40) & (df['HSI'] <= 70)
            df.loc[(medium_sustain | high_sustain) & (medium_health | high_health), 'recommended_level'] = 'Recommended'
        
        logger.info("‚úÖ Feature engineering completed")
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Feature engineering error: {e}")
        return df

def get_data_summary(df: pd.DataFrame) -> Dict[str, Any]:
    """
    DataFrame √∂sszefoglal√≥ statisztik√°k
    
    Args:
        df: Elemzend≈ë DataFrame
    
    Returns:
        Statisztik√°k dictionary
    """
    try:
        summary = {
            'total_records': len(df),
            'columns': list(df.columns),
            'missing_data': df.isnull().sum().to_dict(),
            'data_types': df.dtypes.astype(str).to_dict()
        }
        
        # Numerikus oszlopok statisztik√°i
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        if len(numeric_columns) > 0:
            summary['numeric_stats'] = df[numeric_columns].describe().to_dict()
        
        # Kategorikus oszlopok statisztik√°i
        categorical_columns = df.select_dtypes(include=['object']).columns
        if len(categorical_columns) > 0:
            summary['categorical_stats'] = {}
            for col in categorical_columns:
                if len(df[col].unique()) < 20:  # Csak kis sz√°m√∫ egyedi √©rt√©k≈± oszlopok
                    summary['categorical_stats'][col] = df[col].value_counts().to_dict()
        
        # Specifikus recept statisztik√°k
        if 'composite_score' in df.columns:
            summary['score_distribution'] = {
                'mean': float(df['composite_score'].mean()),
                'median': float(df['composite_score'].median()),
                'std': float(df['composite_score'].std()),
                'min': float(df['composite_score'].min()),
                'max': float(df['composite_score'].max())
            }
        
        return summary
        
    except Exception as e:
        logger.error(f"‚ùå Summary generation error: {e}")
        return {'error': str(e)}

# Export
__all__ = [
    'normalize_esi_scores',
    'calculate_composite_scores', 
    'clean_recipe_data',
    'validate_recipe_dataframe',
    'add_feature_engineering',
    'get_data_summary'
]
